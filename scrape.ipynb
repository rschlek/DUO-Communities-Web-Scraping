{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all page data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './chromedriver_ver110.exe'\n",
    "\n",
    "ser = Service(PATH)\n",
    "\n",
    "chrome_options = Options()\n",
    "#chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "driver = webdriver.Chrome(service=ser,options=chrome_options)\n",
    "\n",
    "url = 'https://community.duo.com/latest?order=activity'\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "# Scroll to bottom of page to load all posts\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True:\n",
    "    # Scroll down to the bottom.\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    # Wait to load the page.\n",
    "    time.sleep(2)\n",
    "    # Calculate new scroll height and compare with last scroll height.\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "# Get all posts\n",
    "content = driver.page_source\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Goal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project goal is to add all the posts into a dataframe in a cleaned manner\n",
    "\n",
    "First, I will get a list of all the links for all the posts. Then, I will visit each of those links and gather all the post information into a new dataframe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather Post Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "post_content = soup.find_all(class_='title raw-link raw-topic-link')\n",
    "\n",
    "links = [item.get('href').split('\"')[0] for item in post_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'https://community.duo.com'\n",
    "\n",
    "links = [prefix + link if not link.startswith(prefix) else link for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 links ['https://community.duo.com/t/popular-duo-videos-how-to-setup-thread/12557', 'https://community.duo.com/t/what-training-content-would-you-like-to-see/4691', 'https://community.duo.com/t/disabling-vs-deleting-a-user/5121']\n",
      "Last 3 links: ['https://community.duo.com/t/community-guidelines/59', 'https://community.duo.com/t/terms-and-conditions/58', 'https://community.duo.com/t/copyright-dispute-policy/57']\n",
      "Total Number of Links: 2980\n"
     ]
    }
   ],
   "source": [
    "print('First 3 links',links[:3])\n",
    "print('Last 3 links:',links[-3:])\n",
    "\n",
    "print('Total Number of Links:',len(links))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: We can expect to have a minimum of 2980 posts. If anything under that amount, there was something wrong with selenium and you should try to run the script again. The last post should be https://community.duo.com/t/copyright-dispute-policy/57/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the data within the posts. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data points I would like to capture as a pilot:\n",
    "\n",
    "1. Post title\n",
    "2. post category(s) (will be seperated by delimiter)\n",
    "3. post tag(s) (will be seperated by delimiter)\n",
    "4. Post user\n",
    "5. Post date\n",
    "6. Post content (will be tricky with images, I am thinking that I will only capture the text portion of the post for now)\n",
    "7. Views\n",
    "8. Replies\n",
    "9. Users\n",
    "10. Links\n",
    "\n",
    "BONUS:\n",
    "\n",
    "A column that indicates if the title or column contains 'Admin' or 'admin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    # Get page\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content,'html.parser')\n",
    "    \n",
    "    # Get Title\n",
    "    title = soup.title.string.split(' - ')[0]\n",
    "\n",
    "    # Get Categories\n",
    "    categories = ' | '.join(soup.title.string.split(' - ')[1:])\n",
    "\n",
    "    # Get Tags\n",
    "    tags_element = soup.find('div', {'class': 'discourse-tags list-tags'})\n",
    "    tags = tags_element.text.strip().replace('\\n', '').replace(' ', '').replace(',', ' | ') if tags_element is not None else None\n",
    "\n",
    "    # Get User Link\n",
    "    hrefs = [link.get('href') for link in soup.find_all('a')]\n",
    "    user_link = next((link for link in hrefs if link.startswith('https://community.duo.com/u/')), None)\n",
    "\n",
    "    # Get User Name from User Link\n",
    "    username = user_link.split('/')[-1]\n",
    "\n",
    "    # Get Date\n",
    "    date = str(soup.find('time', {'class': 'post-time'})['datetime'][:10])\n",
    "\n",
    "    # Get Content\n",
    "    post_content = '\\n'.join(tag.get_text(strip=True) for tag in soup.find('div', {'class': 'post', 'itemprop': 'articleBody'}).find_all(['p','h2','h3','ul','li']))\n",
    "\n",
    "    return url, title, categories, tags, username, user_link, date, post_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://community.duo.com/t/popular-duo-videos-how-to-setup-thread/12557',\n",
       " 'Popular Duo Videos: How-To/Setup Thread',\n",
       " 'Protecting Applications forum | Duo Security Community',\n",
       " None,\n",
       " 'VideoCody',\n",
       " 'https://community.duo.com/u/VideoCody',\n",
       " '2022-06-30',\n",
       " 'This thread serves as an opportunity to highlight some of our most popular Service Integration & Application videos for getting the most out of Duo.\\nAs you probably know, Duo technical setup videos can also be found on corresponding documentation pages atduo.com/docs, as well as incorporated into our educational content on theDuo Level Uplearning platform.\\nTo stay up to date withallDuo videos, including feature and marketing content, please subscribe onYouTubeand turn on all notifications for the channel.\\nCheers,Cody')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://community.duo.com/t/popular-duo-videos-how-to-setup-thread/12557')\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "\n",
    "get_data('https://community.duo.com/t/popular-duo-videos-how-to-setup-thread/12557')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the beautiful soup library is unable to get the section of the html with post views, replies, users, or links. If that is information that is important in the future, we can explore other avenues to get those data points."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Data Frame with Transformed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['URL','POST_TITLE','POST_CATEGORIES','POST_TAGS','POST_USER','POST_USER_LINK','POST_DATE','POST_CONTENT']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for link in links:\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content,'html.parser')\n",
    "    \n",
    "    # Get Title\n",
    "    title = soup.title.string.split(' - ')[0]\n",
    "\n",
    "    # Get Categories\n",
    "    categories = ' | '.join(soup.title.string.split(' - ')[1:-1])\n",
    "\n",
    "    # Get Tags\n",
    "    tags_element = soup.find('div', {'class': 'discourse-tags list-tags'})\n",
    "    tags = tags_element.text.strip().replace('\\n', '').replace(' ', '').replace(',', ' | ') if tags_element is not None else None\n",
    "\n",
    "    # Get User Link\n",
    "    hrefs = [link.get('href') for link in soup.find_all('a')]\n",
    "    user_link = next((link for link in hrefs if link.startswith('https://community.duo.com/u/')), None)\n",
    "\n",
    "    # Get User Name from User Link\n",
    "    username = user_link.split('/')[-1]\n",
    "\n",
    "    # Get Date\n",
    "    date = str(soup.find('time', {'class': 'post-time'})['datetime'][:10])\n",
    "\n",
    "    # Get Content\n",
    "    post_content = '\\n'.join(tag.get_text(strip=True) for tag in soup.find('div', {'class': 'post', 'itemprop': 'articleBody'}).find_all(['p','h2','h3','ul','li']))\n",
    "    print(link, title, categories, tags, username, user_link, date, post_content)\n",
    "    data = pd.Series([link, title, categories, tags, username, user_link, date, post_content], index=columns)\n",
    "    df = df.append(data,ignore_index=True)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADMIN_FFLAG'] = df['POST_CONTENT'].str.contains('admin|Admin').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('duo_community_posts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "634c311e3230fef938d2c5c210de455887ddede028bf312114aac755b73477c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
